import os
import pandas as pd
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

vectorstore = None
retriever = None
llm = None

def initialize_rag():
    global vectorstore, retriever, llm
    
    possible_files = ['present_dataset.xlsx - naver_gift_recommendation_datas.csv', 'present_dataset.csv', 'present_dataset.xlsx']
    file_path = next((f for f in possible_files if os.path.exists(f)), None)
    
    if not file_path:
        print("âŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path, engine='openpyxl')
        df = df.fillna('')
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    documents = []
    for _, row in df.iterrows():
        text_content = f"ìƒí’ˆ: {row.get('title','')} | ê°€ê²©: {row.get('lprice','')} | ì¹´í…Œê³ ë¦¬: {row.get('category1','')} {row.get('category2','')} {row.get('category3','')}"
        metadata = {
            "title": str(row.get('title', '')),
            "lprice": str(row.get('lprice', '')),
            "link": str(row.get('link', '')),
            "image": str(row.get('image', '')),
            "mallName": str(row.get('mallName', 'ë„¤ì´ë²„ì‡¼í•‘'))
        }
        documents.append(Document(page_content=text_content, metadata=metadata))

    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âš ï¸ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸ“¥ ì„ë² ë”© ìƒì„± ì¤‘... (OpenAI text-embedding-3-small)")
    try:
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=openai_key
        )
        vectorstore = FAISS.from_documents(documents, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 6})
        print("âœ… ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    print("â˜ï¸ LLM ì—°ê²° ì¤‘...")
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            openai_api_key=openai_key
        )
        print("âœ… LLM ì—°ê²° ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ OpenAI ì—°ê²° ì‹¤íŒ¨: {e}")
        llm = None

    print("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

# --- Helper Functions ---
def convert_keywords_to_query(kw: dict) -> str:
    return f"ì„ ë¬¼ ë°›ëŠ” ì‚¬ëŒì€ {kw.get('age', '')}ì„¸ {kw.get('gender', '')}ì´ë©°, ê´€ê³„ëŠ” '{kw.get('relationship', '')}'ì…ë‹ˆë‹¤. í˜„ì¬ '{kw.get('situation', '')}' ìƒí™©ì— ë§ëŠ” ì„ ë¬¼ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤."

def convert_survey_to_query(ans: dict) -> str:
    traits = []
    def get_score(q1_key, q2_key):
        score = 0
        if ans.get(q1_key) == 'A': score += 1
        if ans.get(q2_key) == 'A': score += 1
        return score

    score_e = get_score('q1', 'q2')
    if score_e == 2: traits.append("ì‚¬êµì ì´ê³  í™œë™ì ì´ë©° ì‚¬ëŒë“¤ê³¼ì˜ ë§Œë‚¨ê³¼ ìƒˆë¡œìš´ ê²½í—˜ì„ ì¦ê¸°ëŠ” í¸ì…ë‹ˆë‹¤")
    elif score_e == 1: traits.append("ìƒí™©ì— ë”°ë¼ ì‚¬ëŒë“¤ê³¼ì˜ ë§Œë‚¨ì´ë‚˜ ì™¸ë¶€ í™œë™ì„ ì¦ê¸°ëŠ” í¸ì…ë‹ˆë‹¤")
    else: traits.append("ì°¨ë¶„í•˜ê³  ì¡°ìš©í•œ í™˜ê²½ì„ ì„ í˜¸í•˜ë©° ì‹¤ë‚´ í™œë™ì„ í¸ì•ˆí•˜ê²Œ ëŠë¼ëŠ” í¸ì…ë‹ˆë‹¤")

    score_a = get_score('q3', 'q4')
    if score_a == 2: traits.append("íƒ€ì¸ì˜ ê°ì •ì— ë¯¼ê°í•˜ê³  ê°ˆë“±ì„ ë¶€ë“œëŸ½ê²Œ í•´ê²°í•˜ëŠ” ë°°ë ¤ì‹¬ ë§ì€ ì„±í–¥ì…ë‹ˆë‹¤")
    elif score_a == 1: traits.append("ìƒí™©ì— ë”°ë¼ ë°°ë ¤ì‹¬ì„ ë³´ì´ì§€ë§Œ ê°ˆë“± í•´ê²° ë°©ì‹ì€ ì¤‘ê°„ ì •ë„ì…ë‹ˆë‹¤")
    else: traits.append("íƒ€ì¸ì˜ ê°ì •ë³´ë‹¤ ìì‹ ì˜ ê¸°ì¤€ì„ ìš°ì„ ì‹œí•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤")

    score_c = get_score('q5', 'q6')
    if score_c == 2: traits.append("ê³„íšì ì´ê³  ì‹¤ìš©ì ì¸ ê²ƒì„ ì„ í˜¸í•˜ë©°, ê¼¼ê¼¼í•˜ê³  ì±…ì„ê° ìˆëŠ” ì„±í–¥ì…ë‹ˆë‹¤")
    elif score_c == 1: traits.append("ì‹¤ìš©ì„±ê³¼ ê°ì„±ì„ ì ì ˆíˆ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ëŠ” ì„±í–¥ì…ë‹ˆë‹¤")
    else: traits.append("ê³„íšì ì´ê¸°ë³´ë‹¤ëŠ” ì¦‰í¥ì ì´ê³  ê°ì„±ì ì¸ ìš”ì†Œë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ëŠë¼ëŠ” ì„±í–¥ì…ë‹ˆë‹¤")

    score_n = get_score('q7', 'q8')
    if score_n == 2: traits.append("ìŠ¤íŠ¸ë ˆìŠ¤ì— ì·¨ì•½í•œ í¸ì´ë©°, ì•ˆì •ê°ê³¼ í¸ì•ˆí•¨ì„ ì£¼ëŠ” ê²ƒì„ ì„ í˜¸í•©ë‹ˆë‹¤")
    elif score_n == 1: traits.append("ìƒí™©ì— ë”°ë¼ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì„ ìˆ˜ ìˆìœ¼ë©° ì–´ëŠ ì •ë„ ì•ˆì •ê°ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤")
    else: traits.append("ê°ì • ê¸°ë³µì´ ì ê³  ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©ì—ì„œë„ ë¹„êµì  ì•ˆì •ì ì¸ í¸ì…ë‹ˆë‹¤")

    score_o = get_score('q9', 'q10')
    if score_o == 2: traits.append("ìƒˆë¡œìš´ í™œë™ì´ë‚˜ ë…ì°½ì ì¸ ì•„ì´ë””ì–´ì— ì—´ë ¤ ìˆìœ¼ë©° ê°ê°ì ì´ê³  ì°½ì˜ì ì¸ ìŠ¤íƒ€ì¼ì„ ì¢‹ì•„í•©ë‹ˆë‹¤")
    elif score_o == 1: traits.append("ìƒˆë¡œìš´ ê²½í—˜ì—ë„ ì—´ë ¤ ìˆìœ¼ë©´ì„œ ìµìˆ™í•œ ìŠ¤íƒ€ì¼ë„ ì„ í˜¸í•˜ëŠ” ê· í˜• ì¡íŒ ì„±í–¥ì…ë‹ˆë‹¤")
    else: traits.append("ìµìˆ™í•˜ê³  ì „í†µì ì¸ ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•˜ë©° ë³€í™”ë³´ë‹¤ëŠ” ì•ˆì •ê°ì„ í¸ì•ˆí•˜ê²Œ ëŠë‚ë‹ˆë‹¤")

    return f"ì´ ì‚¬ëŒì€ {', '.join(traits)}. ì´ ì‚¬ëŒì—ê²Œ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ì„ ë¬¼ì„ ì¶”ì²œí•´ì¤˜."

# --- [Function 1] ì„¤ë¬¸ì¡°ì‚¬ ì¶”ì²œ í•¨ìˆ˜ (ê¸°ì¡´ ë¡œì§) ---
def get_survey_recommendation(user_query: str):
    if not retriever or not llm:
        return None

    searched_docs = retriever.invoke(user_query)
    product_context = "\n".join([f"- {d.page_content}" for d in searched_docs])
    
    template = """
    ë‹¹ì‹ ì€ ì„ ë¬¼ ì¶”ì²œ ì „ë¬¸ê°€ 'Gift4U'ì…ë‹ˆë‹¤.
    
    [ì‚¬ìš©ì ì…ë ¥ ì •ë³´]
    "{user_query}"
    
    [ê²€ìƒ‰ëœ ìƒí’ˆ í›„ë³´]
    {product_context}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹(ANALYSIS, REASONING, MESSAGE)ì„ ì§€ì¼œì£¼ì„¸ìš”.
    
    [ì¶œë ¥ í˜•ì‹]:
    ANALYSIS: (ì„±í–¥ ë° ìƒí™© ë¶„ì„)
    REASONING: (ì¶”ì²œ ì´ìœ )
    MESSAGE: (ì¹´ë“œ ë©”ì‹œì§€)
    """
    
    prompt = PromptTemplate.from_template(template)
    chain = prompt | llm | StrOutputParser()
    
    try:
        response_text = chain.invoke({"user_query": user_query, "product_context": product_context})
        analysis, reasoning, message = parse_llm_response(response_text)
        
    except Exception as e:
        print(f"âŒ OpenAI Error: {e}")
        analysis, reasoning, message = "ë¶„ì„ ì˜¤ë¥˜", "ì¶”ì²œ ì˜¤ë¥˜", "ë©”ì‹œì§€ ìƒì„± ì˜¤ë¥˜"

    gift_list = []
    for doc in searched_docs:
        gift_list.append({
            "title": doc.metadata.get("title", ""),
            "link": doc.metadata.get("link", ""),
            "image": doc.metadata.get("image", ""),
            "lprice": doc.metadata.get("lprice", ""),
            "mallName": doc.metadata.get("mallName", "")
        })

    return {
        "analysis": analysis,
        "reasoning": reasoning,
        "card_message": message,
        "giftList": gift_list
    }

# --- [Function 2] í‚¤ì›Œë“œ ì¶”ì²œ í•¨ìˆ˜ (ì‹ ê·œ ë¡œì§) ---
def get_keyword_recommendation(keyword_dict: dict):
    if not retriever or not llm:
        return None

    # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ë³€í™˜
    user_query = convert_keywords_to_query(keyword_dict)
    
    # 2. ìœ ì‚¬ë„ ê²€ìƒ‰
    searched_docs = retriever.invoke(user_query)
    product_context = "\n".join([f"- {d.page_content}" for d in searched_docs])
    
    # 3. keywordText ìƒì„± (ê·œì¹™ ê¸°ë°˜)
    # ì˜ˆ: "20ëŒ€ ì—°ì¸ 1ì£¼ë…„ ê¸°ë…ì¼ì—ëŠ” ì´ëŸ° ì„ ë¬¼ì„ ì¶”ì²œí•´ìš”"
    age = keyword_dict.get('age', '')
    relation = keyword_dict.get('relationship', '')
    situation = keyword_dict.get('situation', '')
    keyword_text = f"{age} {relation} {situation}ì—ëŠ” ì´ëŸ° ì„ ë¬¼ì„ ì¶”ì²œí•´ìš”"

    # 4. LLM ë©”ì‹œì§€ ìƒì„± (ì˜¤ì§ ë©”ì‹œì§€ë§Œ ìƒì„±)
    template = """
    ë‹¹ì‹ ì€ ì„ ë¬¼ ì¶”ì²œ ì „ë¬¸ê°€ 'Gift4U'ì…ë‹ˆë‹¤.
    
    ì‚¬ìš©ì ì •ë³´: "{user_query}"
    ì¶”ì²œëœ ìƒí’ˆë“¤: {product_context}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„ ë¬¼ê³¼ í•¨ê»˜ ë³´ë‚¼ ì„¼ìŠ¤ìˆê³  ê°ë™ì ì¸ [ì¹´ë“œ ë©”ì‹œì§€] í•˜ë‚˜ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ë©”ì‹œì§€ ë‚´ìš©ë§Œ ë°”ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
    """
    
    prompt = PromptTemplate.from_template(template)
    chain = prompt | llm | StrOutputParser()
    
    try:
        card_message = chain.invoke({"user_query": user_query, "product_context": product_context})
        card_message = card_message.strip().replace('"', '') # ë”°ì˜´í‘œ ì œê±° ë“± ì •ì œ
    except Exception as e:
        print(f"âŒ OpenAI Error: {e}")
        card_message = "í–‰ë³µí•œ í•˜ë£¨ ë˜ì„¸ìš”!"

    # 5. ì„ ë¬¼ ë¦¬ìŠ¤íŠ¸ ë§¤í•‘
    gift_list = []
    for doc in searched_docs:
        gift_list.append({
            "title": doc.metadata.get("title", ""),
            "link": doc.metadata.get("link", ""),
            "image": doc.metadata.get("image", ""),
            "lprice": doc.metadata.get("lprice", ""),
            "mallName": doc.metadata.get("mallName", "")
        })

    # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜ (ëª…ì„¸ì„œ í˜•ì‹ì— ë§ì¶¤)
    return {
        "age": keyword_dict.get('age'),
        "gender": keyword_dict.get('gender'),
        "relationship": keyword_dict.get('relationship'),
        "situation": keyword_dict.get('situation'),
        "keywordText": keyword_text,
        "card_message": card_message,
        "giftList": gift_list
    }

def parse_llm_response(text):
    analysis = ""
    reasoning = ""
    message = ""
    current_section = None
    for line in text.split('\n'):
        line = line.strip()
        if "ANALYSIS:" in line:
            current_section = "analysis"
            analysis += line.replace("ANALYSIS:", "").strip() + " "
        elif "REASONING:" in line:
            current_section = "reasoning"
            reasoning += line.replace("REASONING:", "").strip() + " "
        elif "MESSAGE:" in line:
            current_section = "message"
            message += line.replace("MESSAGE:", "").strip() + " "
        elif current_section == "analysis":
            analysis += line + " "
        elif current_section == "reasoning":
            reasoning += line + " "
        elif current_section == "message":
            message += line + " "
    return analysis.strip(), reasoning.strip(), message.strip()